{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acoustic-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2017 Google Inc.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Sample that implements a gRPC client for the Google Assistant API.\"\"\"\n",
    "\n",
    "import concurrent.futures\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import os.path\n",
    "import pathlib2 as pathlib\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "import click\n",
    "import grpc\n",
    "import google.auth.transport.grpc\n",
    "import google.auth.transport.requests\n",
    "import google.oauth2.credentials\n",
    "\n",
    "from google.assistant.embedded.v1alpha2 import (\n",
    "    embedded_assistant_pb2,\n",
    "    embedded_assistant_pb2_grpc\n",
    ")\n",
    "from tenacity import retry, stop_after_attempt, retry_if_exception\n",
    "\n",
    "try:\n",
    "    from . import (\n",
    "        assistant_helpers,\n",
    "        audio_helpers,\n",
    "        browser_helpers,\n",
    "        device_helpers\n",
    "    )\n",
    "except (SystemError, ImportError):\n",
    "    import assistant_helpers\n",
    "    import audio_helpers\n",
    "    import browser_helpers\n",
    "    import device_helpers\n",
    "\n",
    "\n",
    "ASSISTANT_API_ENDPOINT = 'embeddedassistant.googleapis.com'\n",
    "END_OF_UTTERANCE = embedded_assistant_pb2.AssistResponse.END_OF_UTTERANCE\n",
    "DIALOG_FOLLOW_ON = embedded_assistant_pb2.DialogStateOut.DIALOG_FOLLOW_ON\n",
    "CLOSE_MICROPHONE = embedded_assistant_pb2.DialogStateOut.CLOSE_MICROPHONE\n",
    "PLAYING = embedded_assistant_pb2.ScreenOutConfig.PLAYING\n",
    "DEFAULT_GRPC_DEADLINE = 60 * 3 + 5\n",
    "\n",
    "\n",
    "class SampleAssistant(object):\n",
    "    \"\"\"Sample Assistant that supports conversations and device actions.\n",
    "\n",
    "    Args:\n",
    "      device_model_id: identifier of the device model.\n",
    "      device_id: identifier of the registered device instance.\n",
    "      conversation_stream(ConversationStream): audio stream\n",
    "        for recording query and playing back assistant answer.\n",
    "      channel: authorized gRPC channel for connection to the\n",
    "        Google Assistant API.\n",
    "      deadline_sec: gRPC deadline in seconds for Google Assistant API call.\n",
    "      device_handler: callback for device actions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, language_code, device_model_id, device_id,\n",
    "                 conversation_stream, display,\n",
    "                 channel, deadline_sec, device_handler):\n",
    "        self.language_code = language_code\n",
    "        self.device_model_id = device_model_id\n",
    "        self.device_id = device_id\n",
    "        self.conversation_stream = conversation_stream\n",
    "        self.display = display\n",
    "\n",
    "        # Opaque blob provided in AssistResponse that,\n",
    "        # when provided in a follow-up AssistRequest,\n",
    "        # gives the Assistant a context marker within the current state\n",
    "        # of the multi-Assist()-RPC \"conversation\".\n",
    "        # This value, along with MicrophoneMode, supports a more natural\n",
    "        # \"conversation\" with the Assistant.\n",
    "        self.conversation_state = None\n",
    "        # Force reset of first conversation.\n",
    "        self.is_new_conversation = True\n",
    "\n",
    "        # Create Google Assistant API gRPC client.\n",
    "        self.assistant = embedded_assistant_pb2_grpc.EmbeddedAssistantStub(\n",
    "            channel\n",
    "        )\n",
    "        self.deadline = deadline_sec\n",
    "\n",
    "        self.device_handler = device_handler\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, etype, e, traceback):\n",
    "        if e:\n",
    "            return False\n",
    "        self.conversation_stream.close()\n",
    "\n",
    "    def is_grpc_error_unavailable(e):\n",
    "        is_grpc_error = isinstance(e, grpc.RpcError)\n",
    "        if is_grpc_error and (e.code() == grpc.StatusCode.UNAVAILABLE):\n",
    "            logging.error('grpc unavailable error: %s', e)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    @retry(reraise=True, stop=stop_after_attempt(3),\n",
    "           retry=retry_if_exception(is_grpc_error_unavailable))\n",
    "    def assist(self):\n",
    "        \"\"\"Send a voice request to the Assistant and playback the response.\n",
    "\n",
    "        Returns: True if conversation should continue.\n",
    "        \"\"\"\n",
    "        continue_conversation = False\n",
    "        device_actions_futures = []\n",
    "\n",
    "        self.conversation_stream.start_recording()\n",
    "        logging.info('Recording audio request.')\n",
    "\n",
    "        def iter_log_assist_requests():\n",
    "            for c in self.gen_assist_requests():\n",
    "                assistant_helpers.log_assist_request_without_audio(c)\n",
    "                yield c\n",
    "            logging.debug('Reached end of AssistRequest iteration.')\n",
    "\n",
    "        # This generator yields AssistResponse proto messages\n",
    "        # received from the gRPC Google Assistant API.\n",
    "        for resp in self.assistant.Assist(iter_log_assist_requests(),\n",
    "                                          self.deadline):\n",
    "            assistant_helpers.log_assist_response_without_audio(resp)\n",
    "            if resp.event_type == END_OF_UTTERANCE:\n",
    "                logging.info('End of audio request detected.')\n",
    "                logging.info('Stopping recording.')\n",
    "                self.conversation_stream.stop_recording()\n",
    "            if resp.speech_results:\n",
    "                logging.info('Transcript of user request: \"%s\".',\n",
    "                             ' '.join(r.transcript\n",
    "                                      for r in resp.speech_results))\n",
    "            if len(resp.audio_out.audio_data) > 0:\n",
    "                if not self.conversation_stream.playing:\n",
    "                    self.conversation_stream.stop_recording()\n",
    "                    self.conversation_stream.start_playback()\n",
    "                    logging.info('Playing assistant response.')\n",
    "                self.conversation_stream.write(resp.audio_out.audio_data)\n",
    "            if resp.dialog_state_out.conversation_state:\n",
    "                conversation_state = resp.dialog_state_out.conversation_state\n",
    "                logging.debug('Updating conversation state.')\n",
    "                self.conversation_state = conversation_state\n",
    "            if resp.dialog_state_out.volume_percentage != 0:\n",
    "                volume_percentage = resp.dialog_state_out.volume_percentage\n",
    "                logging.info('Setting volume to %s%%', volume_percentage)\n",
    "                self.conversation_stream.volume_percentage = volume_percentage\n",
    "            if resp.dialog_state_out.microphone_mode == DIALOG_FOLLOW_ON:\n",
    "                continue_conversation = True\n",
    "                logging.info('Expecting follow-on query from user.')\n",
    "            elif resp.dialog_state_out.microphone_mode == CLOSE_MICROPHONE:\n",
    "                continue_conversation = False\n",
    "            if resp.device_action.device_request_json:\n",
    "                device_request = json.loads(\n",
    "                    resp.device_action.device_request_json\n",
    "                )\n",
    "                fs = self.device_handler(device_request)\n",
    "                if fs:\n",
    "                    device_actions_futures.extend(fs)\n",
    "            if self.display and resp.screen_out.data:\n",
    "                system_browser = browser_helpers.system_browser\n",
    "                system_browser.display(resp.screen_out.data)\n",
    "\n",
    "        if len(device_actions_futures):\n",
    "            logging.info('Waiting for device executions to complete.')\n",
    "            concurrent.futures.wait(device_actions_futures)\n",
    "\n",
    "        logging.info('Finished playing assistant response.')\n",
    "        self.conversation_stream.stop_playback()\n",
    "        return continue_conversation\n",
    "\n",
    "    def gen_assist_requests(self):\n",
    "        \"\"\"Yields: AssistRequest messages to send to the API.\"\"\"\n",
    "\n",
    "        config = embedded_assistant_pb2.AssistConfig(\n",
    "            audio_in_config=embedded_assistant_pb2.AudioInConfig(\n",
    "                encoding='LINEAR16',\n",
    "                sample_rate_hertz=self.conversation_stream.sample_rate,\n",
    "            ),\n",
    "            audio_out_config=embedded_assistant_pb2.AudioOutConfig(\n",
    "                encoding='LINEAR16',\n",
    "                sample_rate_hertz=self.conversation_stream.sample_rate,\n",
    "                volume_percentage=self.conversation_stream.volume_percentage,\n",
    "            ),\n",
    "            dialog_state_in=embedded_assistant_pb2.DialogStateIn(\n",
    "                language_code=self.language_code,\n",
    "                conversation_state=self.conversation_state,\n",
    "                is_new_conversation=self.is_new_conversation,\n",
    "            ),\n",
    "            device_config=embedded_assistant_pb2.DeviceConfig(\n",
    "                device_id=self.device_id,\n",
    "                device_model_id=self.device_model_id,\n",
    "            )\n",
    "        )\n",
    "        if self.display:\n",
    "            config.screen_out_config.screen_mode = PLAYING\n",
    "        # Continue current conversation with later requests.\n",
    "        self.is_new_conversation = False\n",
    "        # The first AssistRequest must contain the AssistConfig\n",
    "        # and no audio data.\n",
    "        yield embedded_assistant_pb2.AssistRequest(config=config)\n",
    "        for data in self.conversation_stream:\n",
    "            # Subsequent requests need audio data, but not config.\n",
    "            yield embedded_assistant_pb2.AssistRequest(audio_in=data)\n",
    "\n",
    "def main(\n",
    "    project_id,\n",
    "    device_model_id,\n",
    "    device_id=None,\n",
    "    input_audio_file=None,\n",
    "    output_audio_file=None,\n",
    "    api_endpoint=ASSISTANT_API_ENDPOINT,\n",
    "    credentials=os.path.join(click.get_app_dir('google-oauthlib-tool'),'credentials.json'),\n",
    "    device_config=os.path.join(click.get_app_dir('googlesamples-assistant'), 'device_config.json'),\n",
    "    lang='en-US',\n",
    "    display=False,\n",
    "    verbose=False,\n",
    "    audio_sample_rate=audio_helpers.DEFAULT_AUDIO_SAMPLE_RATE,\n",
    "    audio_sample_width=audio_helpers.DEFAULT_AUDIO_SAMPLE_WIDTH,\n",
    "    audio_iter_size=audio_helpers.DEFAULT_AUDIO_ITER_SIZE,\n",
    "    audio_block_size=audio_helpers.DEFAULT_AUDIO_DEVICE_BLOCK_SIZE,\n",
    "    audio_flush_size=audio_helpers.DEFAULT_AUDIO_DEVICE_FLUSH_SIZE,\n",
    "    grpc_deadline=DEFAULT_GRPC_DEADLINE,\n",
    "    once=False,\n",
    "    *args, **kwargs\n",
    "):\n",
    "    \"\"\"Samples for the Google Assistant API.\n",
    "\n",
    "    Examples:\n",
    "      Run the sample with microphone input and speaker output:\n",
    "\n",
    "        $ python -m googlesamples.assistant\n",
    "\n",
    "      Run the sample with file input and speaker output:\n",
    "\n",
    "        $ python -m googlesamples.assistant -i <input file>\n",
    "\n",
    "      Run the sample with file input and output:\n",
    "\n",
    "        $ python -m googlesamples.assistant -i <input file> -o <output file>\n",
    "    \"\"\"\n",
    "    # Setup logging.\n",
    "    logging.basicConfig(level=logging.DEBUG if verbose else logging.INFO)\n",
    "\n",
    "    # Load OAuth 2.0 credentials.\n",
    "    try:\n",
    "        with open(credentials, 'r') as f:\n",
    "            credentials = google.oauth2.credentials.Credentials(token=None,\n",
    "                                                                **json.load(f))\n",
    "            http_request = google.auth.transport.requests.Request()\n",
    "            credentials.refresh(http_request)\n",
    "    except Exception as e:\n",
    "        logging.error('Error loading credentials: %s', e)\n",
    "        logging.error('Run google-oauthlib-tool to initialize '\n",
    "                      'new OAuth 2.0 credentials.')\n",
    "        sys.exit(-1)\n",
    "\n",
    "    # Create an authorized gRPC channel.\n",
    "    grpc_channel = google.auth.transport.grpc.secure_authorized_channel(\n",
    "        credentials, http_request, api_endpoint)\n",
    "    logging.info('Connecting to %s', api_endpoint)\n",
    "\n",
    "    # Configure audio source and sink.\n",
    "    audio_device = None\n",
    "    if input_audio_file:\n",
    "        audio_source = audio_helpers.WaveSource(\n",
    "            open(input_audio_file, 'rb'),\n",
    "            sample_rate=audio_sample_rate,\n",
    "            sample_width=audio_sample_width\n",
    "        )\n",
    "    else:\n",
    "        audio_source = audio_device = (\n",
    "            audio_device or audio_helpers.SoundDeviceStream(\n",
    "                sample_rate=audio_sample_rate,\n",
    "                sample_width=audio_sample_width,\n",
    "                block_size=audio_block_size,\n",
    "                flush_size=audio_flush_size\n",
    "            )\n",
    "        )\n",
    "    if output_audio_file:\n",
    "        audio_sink = audio_helpers.WaveSink(\n",
    "            open(output_audio_file, 'wb'),\n",
    "            sample_rate=audio_sample_rate,\n",
    "            sample_width=audio_sample_width\n",
    "        )\n",
    "    else:\n",
    "        audio_sink = audio_device = (\n",
    "            audio_device or audio_helpers.SoundDeviceStream(\n",
    "                sample_rate=audio_sample_rate,\n",
    "                sample_width=audio_sample_width,\n",
    "                block_size=audio_block_size,\n",
    "                flush_size=audio_flush_size\n",
    "            )\n",
    "        )\n",
    "    # Create conversation stream with the given audio source and sink.\n",
    "    conversation_stream = audio_helpers.ConversationStream(\n",
    "        source=audio_source,\n",
    "        sink=audio_sink,\n",
    "        iter_size=audio_iter_size,\n",
    "        sample_width=audio_sample_width,\n",
    "    )\n",
    "\n",
    "    if not device_id or not device_model_id:\n",
    "        try:\n",
    "            with open(device_config) as f:\n",
    "                device = json.load(f)\n",
    "                device_id = device['id']\n",
    "                device_model_id = device['model_id']\n",
    "                logging.info(\"Using device model %s and device id %s\",\n",
    "                             device_model_id,\n",
    "                             device_id)\n",
    "        except Exception as e:\n",
    "            logging.warning('Device config not found: %s' % e)\n",
    "            logging.info('Registering device')\n",
    "            if not device_model_id:\n",
    "                logging.error('Option --device-model-id required '\n",
    "                              'when registering a device instance.')\n",
    "                sys.exit(-1)\n",
    "            if not project_id:\n",
    "                logging.error('Option --project-id required '\n",
    "                              'when registering a device instance.')\n",
    "                sys.exit(-1)\n",
    "            device_base_url = (\n",
    "                'https://%s/v1alpha2/projects/%s/devices' % (api_endpoint,\n",
    "                                                             project_id)\n",
    "            )\n",
    "            device_id = str(uuid.uuid1())\n",
    "            payload = {\n",
    "                'id': device_id,\n",
    "                'model_id': device_model_id,\n",
    "                'client_type': 'SDK_SERVICE'\n",
    "            }\n",
    "            session = google.auth.transport.requests.AuthorizedSession(\n",
    "                credentials\n",
    "            )\n",
    "            r = session.post(device_base_url, data=json.dumps(payload))\n",
    "            if r.status_code != 200:\n",
    "                logging.error('Failed to register device: %s', r.text)\n",
    "                sys.exit(-1)\n",
    "            logging.info('Device registered: %s', device_id)\n",
    "            pathlib.Path(os.path.dirname(device_config)).mkdir(exist_ok=True)\n",
    "            with open(device_config, 'w') as f:\n",
    "                json.dump(payload, f)\n",
    "\n",
    "    device_handler = device_helpers.DeviceRequestHandler(device_id)\n",
    "\n",
    "    @device_handler.command('action.devices.commands.OnOff')\n",
    "    def onoff(on):\n",
    "        if on:\n",
    "            logging.info('Turning device on')\n",
    "        else:\n",
    "            logging.info('Turning device off')\n",
    "\n",
    "    @device_handler.command('com.example.commands.BlinkLight')\n",
    "    def blink(speed, number):\n",
    "        logging.info('Blinking device %s times.' % number)\n",
    "        delay = 1\n",
    "        if speed == \"SLOWLY\":\n",
    "            delay = 2\n",
    "        elif speed == \"QUICKLY\":\n",
    "            delay = 0.5\n",
    "        for i in range(int(number)):\n",
    "            logging.info('Device is blinking.')\n",
    "            time.sleep(delay)\n",
    "\n",
    "    with SampleAssistant(lang, device_model_id, device_id,\n",
    "                         conversation_stream, display,\n",
    "                         grpc_channel, grpc_deadline,\n",
    "                         device_handler) as assistant:\n",
    "        # If file arguments are supplied:\n",
    "        # exit after the first turn of the conversation.\n",
    "        if input_audio_file or output_audio_file:\n",
    "            assistant.assist()\n",
    "            return\n",
    "\n",
    "        # If no file arguments supplied:\n",
    "        # keep recording voice requests using the microphone\n",
    "        # and playing back assistant response using the speaker.\n",
    "        # When the once flag is set, don't wait for a trigger. Otherwise, wait.\n",
    "        wait_for_user_trigger = not once\n",
    "        while True:\n",
    "            if wait_for_user_trigger:\n",
    "                click.pause(info='Press Enter to send a new request...')\n",
    "            continue_conversation = assistant.assist()\n",
    "            # wait for user trigger if there is no follow-up turn in\n",
    "            # the conversation.\n",
    "            wait_for_user_trigger = not continue_conversation\n",
    "\n",
    "            # If we only want one conversation, break.\n",
    "            if once and (not continue_conversation):\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "formal-saying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.SampleAssistant"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SampleAssistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "instant-demand",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Connecting to embeddedassistant.googleapis.com\n",
      "INFO:root:Using device model hey-lumi-hey-lumi-e75s95 and device id 8651d89e-764d-11eb-86c8-4517514454f0\n",
      "INFO:root:Recording audio request.\n",
      "INFO:root:Transcript of user request: \"hey\".\n",
      "INFO:root:Transcript of user request: \"hey\".\n",
      "INFO:root:Transcript of user request: \"hey  wait\".\n",
      "INFO:root:Transcript of user request: \"hey  we\".\n",
      "INFO:root:Transcript of user request: \"hey we\".\n",
      "INFO:root:End of audio request detected.\n",
      "INFO:root:Stopping recording.\n",
      "INFO:root:Transcript of user request: \"hey we\".\n",
      "INFO:root:Playing assistant response.\n",
      "INFO:root:Finished playing assistant response.\n",
      "INFO:root:Recording audio request.\n",
      "INFO:root:Transcript of user request: \"open\".\n",
      "INFO:root:Transcript of user request: \"open new\".\n",
      "INFO:root:Transcript of user request: \"open you\".\n",
      "INFO:root:Transcript of user request: \"open YouTube\".\n",
      "INFO:root:Transcript of user request: \"open  YouTube\".\n",
      "INFO:root:End of audio request detected.\n",
      "INFO:root:Stopping recording.\n",
      "INFO:root:Transcript of user request: \"open YouTube\".\n",
      "INFO:root:Playing assistant response.\n",
      "INFO:root:Finished playing assistant response.\n",
      "INFO:root:Recording audio request.\n",
      "INFO:root:Transcript of user request: \"how is\".\n",
      "INFO:root:Transcript of user request: \"how is the\".\n",
      "INFO:root:Transcript of user request: \"how is the weather\".\n",
      "INFO:root:Transcript of user request: \"how is  the weather\".\n",
      "INFO:root:Transcript of user request: \"how is the  weather\".\n",
      "INFO:root:End of audio request detected.\n",
      "INFO:root:Stopping recording.\n",
      "INFO:root:Transcript of user request: \"how is the weather\".\n",
      "INFO:root:Playing assistant response.\n",
      "INFO:root:Finished playing assistant response.\n",
      "INFO:root:Recording audio request.\n",
      "INFO:root:Transcript of user request: \"flip\".\n",
      "INFO:root:Transcript of user request: \"goodbye\".\n",
      "INFO:root:End of audio request detected.\n",
      "INFO:root:Stopping recording.\n",
      "INFO:root:Transcript of user request: \"goodbye\".\n",
      "INFO:root:Playing assistant response.\n",
      "INFO:root:Finished playing assistant response.\n",
      "INFO:root:Recording audio request.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-879c437144ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m main(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mproject_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hey-lumi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdevice_model_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hey-lumi-hey-lumi-e75s95'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/home/rakumairu/projects/jendela/wakeword/credentials.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-11-64582410bda9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(project_id, device_model_id, device_id, input_audio_file, output_audio_file, api_endpoint, credentials, device_config, lang, display, verbose, audio_sample_rate, audio_sample_width, audio_iter_size, audio_block_size, audio_flush_size, grpc_deadline, once, *args, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwait_for_user_trigger\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                 \u001b[0mclick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Press Enter to send a new request...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0mcontinue_conversation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massistant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m             \u001b[0;31m# wait for user trigger if there is no follow-up turn in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;31m# the conversation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             do = self.iter(result=result, exc_info=exc_info,\n\u001b[0m\u001b[1;32m    330\u001b[0m                            start_time=start_time)\n\u001b[1;32m    331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, result, exc_info, start_time)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-64582410bda9>\u001b[0m in \u001b[0;36massist\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# This generator yields AssistResponse proto messages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# received from the gRPC Google Assistant API.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         for resp in self.assistant.Assist(iter_log_assist_requests(),\n\u001b[0m\u001b[1;32m    139\u001b[0m                                           self.deadline):\n\u001b[1;32m    140\u001b[0m             \u001b[0massistant_helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_assist_response_without_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    792\u001b[0m                      and self._state.code is not None))\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m             \u001b[0m_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_response_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/grpc/_common.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(wait_fn, wait_complete_fn, timeout, spin_cb)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwait_complete_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0m_wait_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXIMUM_WAIT_TIMEOUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspin_cb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/grpc/_common.py\u001b[0m in \u001b[0;36m_wait_once\u001b[0;34m(wait_fn, timeout, spin_cb)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wait_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspin_cb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mwait_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspin_cb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mspin_cb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(\n",
    "    project_id='hey-lumi',\n",
    "    device_model_id='hey-lumi-hey-lumi-e75s95',\n",
    "    credentials='/home/rakumairu/projects/jendela/wakeword/credentials.json'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
